{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupational-branch",
   "metadata": {},
   "source": [
    "# Multi-Class Classification & Multi Label Classification Demonstrations\n",
    "\n",
    "As a clothing retailer with an e-Commerce presence, it's important for us to understand what customers are saying about our products, which products are most popular with our customers, and how we can improve our offerings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "photographic-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gereral Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from timeit import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Model Persistence Imports\n",
    "from joblib import dump, load\n",
    "\n",
    "# Test Processing Imports\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# SMOTE Imports\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Plotting Imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-belle",
   "metadata": {},
   "source": [
    "# Preprocessing & EDA\n",
    "\n",
    "Importing our dataset and providing the necessary cleaning and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fatal-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age                    Title  \\\n",
       "0   33                      NaN   \n",
       "1   34                      NaN   \n",
       "2   60  Some major design flaws   \n",
       "3   50         My favorite buy!   \n",
       "4   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count Department Name Class Name  \n",
       "0                        0        Intimate  Intimates  \n",
       "1                        4         Dresses    Dresses  \n",
       "2                        0         Dresses    Dresses  \n",
       "3                        0         Bottoms      Pants  \n",
       "4                        6            Tops    Blouses  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ClothingReviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-senator",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "higher-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Age                      23486 non-null  int64 \n",
      " 1   Title                    19676 non-null  object\n",
      " 2   Review Text              22641 non-null  object\n",
      " 3   Rating                   23486 non-null  int64 \n",
      " 4   Recommended IND          23486 non-null  int64 \n",
      " 5   Positive Feedback Count  23486 non-null  int64 \n",
      " 6   Department Name          23472 non-null  object\n",
      " 7   Class Name               23472 non-null  object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "auburn-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-intervention",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "Nulll values are generally not desireable in a dataset.  In certain cases, observations (rows) with low counts will simply be dropped, in other cases, they can be filled with other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "thirty-theta",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill the NA values with empty string so that we don't drop rows that are only missing a title\n",
    "df['Title'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eleven-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                          0\n",
       "Title                        0\n",
       "Review Text                845\n",
       "Rating                       0\n",
       "Recommended IND              0\n",
       "Positive Feedback Count      0\n",
       "Department Name             14\n",
       "Class Name                  14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "neutral-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "experienced-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Title'] + ' ' + df['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d75ae2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'text_len' that counts the length for the derived field\n",
    "df['text_len'] = df.apply(lambda row: len(row['Text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "parliamentary-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Title', 'Review Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-eleven",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "A common practice is to review any duplicates.  If there are large quantities, they can skew the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "specific-fiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before = 22628\n",
      "After = 22626\n",
      "\n",
      "Total Removed = 2\n"
     ]
    }
   ],
   "source": [
    "len_before = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "len_after = df.shape[0]\n",
    "\n",
    "print(\"Before =\", len_before)\n",
    "# drop duplicates\n",
    "print(\"After =\", len_after)\n",
    "print('')\n",
    "print(\"Total Removed =\", len_before - len_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-native",
   "metadata": {},
   "source": [
    "## Check for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffbb5f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tops        10048\n",
       "Dresses      6145\n",
       "Bottoms      3661\n",
       "Intimate     1652\n",
       "Jackets      1002\n",
       "Trend         118\n",
       "Name: Department Name, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Department Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92a92523",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (df['Class Name'] == 'Chemises') | (df['Class Name'] == 'Casual bottoms')\n",
    "df = df[~filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-crystal",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "For **Parts** of our analysis, the text needs to have some basic transformation for our models to work propertly.  These are as follows:\n",
    "\n",
    "1. **Lower**: Convert all characters to lowercase\n",
    "1. **Remove Punctuation**: In most cases, punctuation doesn't help NLP and ML models and can be removed.\n",
    "1. **Stop Word Removal**: Stop words generally don't add context to analysis (unless the length of text is very short (`100` - `200` characters) and can be removed.\n",
    "1. **Lemmatization**: Words will be reduced to there *Lemma* or root.  This will greatly improve the accuracy of the analysis since words like `simming` and `swimmer` will be reduced to `swim`.\n",
    "\n",
    "**Note**: The orginal text will be preserved for other analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "intense-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dietary-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "    \n",
    "    final_string = \"\"\n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctionation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    # Remove stop words and usless words\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "\n",
    "    # Remove numbers\n",
    "    text_filtered = [re.sub('\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "    \n",
    "    # Stem the text with NLTK PorterStemmer\n",
    "    stemmer = PorterStemmer() \n",
    "    text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    final_string = ' '.join(text_stemmed)\n",
    "    \n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "seeing-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Processed'] = df['Text'].apply(lambda x: process_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "global-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love dress sooo pretti happen find store im glad bc never would order onlin bc petit bought petit  love length hit littl knee would definit true midi someon truli petit'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text_Processed'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-absence",
   "metadata": {},
   "source": [
    "# Sentiment Based Prediction Model:\n",
    "\n",
    "Next, we'll create a Supervised ML model to predict whether a customer will recommend a product based on the text from the review and the sentiment of that text, and the length of the review.\n",
    "\n",
    "To create our model, we will be mixing both text and numeric values.  There are multiple ways to accomplish this, but we will be using a `ColumnTransformer` in a Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4fefd",
   "metadata": {},
   "source": [
    "## Pipeline Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "incident-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipe(clf):\n",
    "    '''Create a pipeline for a given classifier.  The classifier needs to be an instance\n",
    "    of the classifier with all parmeters needed specified.'''\n",
    "    \n",
    "    # Each pipeline uses the same column transformer.  \n",
    "    column_trans = ColumnTransformer(\n",
    "            [('Text', TfidfVectorizer(), 'Text_Processed'),\n",
    "             ('Text Length', MinMaxScaler(), ['text_len'])],\n",
    "            remainder='drop') \n",
    "    \n",
    "    pipeline = Pipeline([('prep',column_trans),\n",
    "                         ('clf', clf)])\n",
    "     \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-darwin",
   "metadata": {},
   "source": [
    "## Model Selection via Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76735c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Text_Processed', 'text_len']]\n",
    "y = df['Class Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "disciplinary-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22624, 2)\n",
      "(22624,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LogReg' : LogisticRegression(random_state=42, \n",
    "                                        class_weight='balanced', \n",
    "                                        max_iter=500),\n",
    "          'RandomForest' : RandomForestClassifier(\n",
    "                                        class_weight='balanced', \n",
    "                                        random_state=42),\n",
    "          'XGBoost' : xgb.XGBClassifier(random_state=42, \n",
    "                                        verbosity=0)\n",
    "          }\n",
    "\n",
    "for name, model, in models.items():\n",
    "    clf = model\n",
    "    pipeline = create_pipe(clf)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, \n",
    "                                 n_repeats=3, \n",
    "                                 random_state=1)\n",
    "    %time scores = cross_val_score(pipeline, X, y, scoring='f1_weighted', cv=cv, n_jobs=1, error_score='raise')\n",
    "    print(name, ': Mean f1 Weighted: %.3f and Standard Deviation: (%.3f)' % \\\n",
    "        (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-devon",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "lined-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-canberra",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "delayed-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_print(pipeline, name):\n",
    "    ''' take a supplied pipeline and run it against the train-test spit \n",
    "    and product scoring results.'''\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "younger-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Blouses      0.545     0.606     0.574       982\n",
      "     Dresses      0.930     0.798     0.859      2037\n",
      "  Fine gauge      0.356     0.399     0.376       351\n",
      "   Intimates      0.278     0.667     0.392        45\n",
      "     Jackets      0.463     0.698     0.556       205\n",
      "       Jeans      0.782     0.771     0.777       354\n",
      "       Knits      0.685     0.464     0.554      1591\n",
      "    Layering      0.073     0.344     0.121        32\n",
      "     Legwear      0.430     0.702     0.533        57\n",
      "      Lounge      0.182     0.260     0.215       215\n",
      "   Outerwear      0.532     0.536     0.534       110\n",
      "       Pants      0.657     0.698     0.676       463\n",
      "      Shorts      0.335     0.663     0.445        89\n",
      "      Skirts      0.756     0.875     0.811       287\n",
      "       Sleep      0.222     0.301     0.256        73\n",
      "    Sweaters      0.555     0.483     0.517       437\n",
      "        Swim      0.733     0.810     0.769       105\n",
      "       Trend      0.015     0.061     0.024        33\n",
      "\n",
      "    accuracy                          0.625      7466\n",
      "   macro avg      0.474     0.563     0.499      7466\n",
      "weighted avg      0.675     0.625     0.641      7466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, \n",
    "                         class_weight='balanced', \n",
    "                         max_iter=500)\n",
    "pipeline = create_pipe(clf)\n",
    "fit_and_print(pipeline, 'LogReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f4b1d",
   "metadata": {},
   "source": [
    "## Persist the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba6627f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiclass.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline, 'multiclass.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-whole",
   "metadata": {},
   "source": [
    "## Test on Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d60bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "pipeline = load('multiclass.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "informed-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(x):\n",
    "    \n",
    "    x = process_string(x)\n",
    "    length = len(x)\n",
    "    \n",
    "    d = {'Text_Processed' : x,\n",
    "        'text_len' : length}\n",
    "\n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "negative-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = ['This dress is gorgeous and I love it and would gladly reccomend it to all of my friends.',\n",
    "        'This skirt has really horible quality and I hate it!',\n",
    "        'A super cute top with the perfect fit.',\n",
    "        'The most gorgeous pair of jeans I have seen.',\n",
    "        'this item is too little and tight.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "blank-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns 1 for Positive reviews and 0 for Negative reviews: \n",
      "\n",
      "This dress is gorgeous and I love it and would gladly reccomend it to all of my friends. = ['Dresses']\n",
      "This skirt has really horible quality and I hate it! = ['Skirts']\n",
      "A super cute top with the perfect fit. = ['Knits']\n",
      "The most gorgeous pair of jeans I have seen. = ['Jeans']\n",
      "this item is too little and tight. = ['Legwear']\n"
     ]
    }
   ],
   "source": [
    "print('Returns 1 for Positive reviews and 0 for Negative reviews:','\\n')\n",
    "for rev in revs:\n",
    "    c_res = pipeline.predict(create_test_data(rev))\n",
    "    print(rev, '=', c_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-delivery",
   "metadata": {},
   "source": [
    "## Multi-Label Classification\n",
    "\n",
    "Next, we'll attempt to create a Supervised Machine Learning model to classify products by Department.  This process looks at the text that a user wrote in a review and determined its Department.\n",
    "\n",
    "An interesting opportunity is to use this information to **cross-sell** or **cross-list** products.  If there is a strong enough probability that an item could be in multiple departments from our analysis, could we **increase sales** with cross-marketing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words\n",
    "df['Department Name'] = df['Department Name'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Text_Processed', 'Department Name']]\n",
    "y = df['Department Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipe(clf):\n",
    "    \n",
    "    # Create the column transfomer\n",
    "    column_trans = ColumnTransformer(\n",
    "            [('Text', TfidfVectorizer(), 'Text_Processed')],\n",
    "            remainder='drop') \n",
    "    \n",
    "    # Build the pipeline\n",
    "    pipeline = Pipeline([('prep',column_trans),\n",
    "                         ('over', SMOTE(random_state=42)),\n",
    "                         ('under', RandomUnderSampler(random_state=42)), \n",
    "                         ('clf', clf)])\n",
    "     \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic Regression' : OneVsRestClassifier(LogisticRegression(max_iter=500, random_state=42)),\n",
    "          'Random Forest' : OneVsRestClassifier(RandomForestClassifier(random_state=42)),\n",
    "          'XGB' : OneVsRestClassifier(xgb.XGBClassifier(random_state=42, verbosity=0))\n",
    "          }\n",
    "\n",
    "for name, model, in models.items():\n",
    "    clf = model\n",
    "    pipeline = create_pipe(clf)\n",
    "    %time scores = cross_val_score(pipeline, X, y, scoring='f1_macro', cv=3, n_jobs=1, error_score='raise')\n",
    "    print(name, ': Mean f1 Macro: %.3f and Standard Deviation: (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-contrast",
   "metadata": {},
   "source": [
    "## Model Building & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Optimization was performed prior to Hyperparemeter selection\n",
    "clf = OneVsRestClassifier(xgb.XGBClassifier(random_state=42, verbosity=0))\n",
    "pipeline = create_pipe(clf)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "score = metrics.f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive the text lables from the MultiLabelBinarizer\n",
    "pred_labels = mlb.inverse_transform(y_pred)\n",
    "\n",
    "# Append them to the DataFrame\n",
    "X_test['Predicted Labels'] = pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of them\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "X_test.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-ownership",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    " - In many cases, our classifier was very accurate in determining the correct Department.  Since we used a multi-label classifier, the algorithm suggested more than one label in some cases.  Upon inspecting these, in some cases, the suggestion of an additional Department is incredibly logical.  \n",
    " - One item in the above list did not receive a predicted label.\n",
    " - Two are showing multiple classes, but in one of these cases, they make sense.  `Jackets` and `Tops`.  For the other, it's classifying it as `Intimate` and `Tops`, which probably would not apply.\n",
    " - There is one misclassified item.  The original class was `Trend`, and the predicted class is `Bottoms` for this skirt.  However, a skirt is a bottom and therefore is correct.  We also do not have many observations in the `Trend` class; therefore, it's harder to be accurate with predictions here, as we noted earlier.\n",
    " - It's possible to use these multi-label classes to investigate **cross-marketing / cross-listing** opportunities for these products.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9eeb6",
   "metadata": {},
   "source": [
    "## Persist the Model\n",
    "\n",
    "Saving both the pipeline as well as the `MultiLabelBinarizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(mlb, 'mlb.joblib') \n",
    "dump(pipeline, 'multiclass.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-database",
   "metadata": {},
   "source": [
    "## Test on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(x):\n",
    "    '''create a dataframe that is in the same format as the Train and Test Data.\n",
    "    ['Bottoms' 'Dresses' 'Intimate' 'Jackets' 'Tops' 'Trend']'''\n",
    "    \n",
    "    s = process_string(x[0])\n",
    "    \n",
    "    d = {'Text_Processed' : s,\n",
    "         'Department Name' : x[1]}\n",
    "\n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = [('This dress is gorgeous and would gladly reccomend it to all of my friends.', ['Dresses']),\n",
    "     ('These pants have really horible quality and I hate them!', ['Bottoms']),\n",
    "     ('A super cute blouse with a great fit.', ['Tops']),\n",
    "     ('The most gorgeous pair of jeans I have seen.', ['Bottoms']),\n",
    "     ('This bra is silky smooth material and fits perfectly.', ['Intimate'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-senate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rev in revs:\n",
    "    c_res = pipeline.predict(create_test_data(rev))\n",
    "    print(rev[0], '\\n', rev[1], '\\n' ,mlb.inverse_transform(c_res), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989afad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc50f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72226195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
